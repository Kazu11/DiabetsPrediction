# -*- coding: utf-8 -*-
"""diabetesprediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17e83d2gz9CUVBaB5qPQxaidruTY-1Qpr

## **Import Libarays**
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from scipy import stats

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold

from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report
from sklearn.metrics import roc_curve, roc_auc_score, precision_score, recall_score, f1_score, RocCurveDisplay

from statistics import stdev
import plotly.express as px
import warnings
warnings.filterwarnings("ignore")

"""# **Load Data & More Information about this data set**"""

data = pd.read_csv('/content/diabetes_prediction_dataset.csv.zip')

samples, features = data.shape
print('Number Of Samples: ', samples)
print('Number Of Features: ', features)

data.head(10)

data.info()

data.describe().T

"""# **unique valuse**"""

d = []
u = []
t = []
for col in data:
    d.append(col)
    u.append(data[col].nunique())
    t.append(data[col].dtype)
pd.DataFrame({'column':d,'type': t ,'unique value' : u})

labels = ['Female', 'Male', 'Other']
values = data['gender'].value_counts().values

plt.style.use('fivethirtyeight')
plt.figure(figsize=(10, 8))
plt.subplot(1, 2, 1)
sns.countplot(x=data['gender'], data=data)
plt.subplot(1, 2, 2)
plt.pie(values, labels=labels, autopct='%1.1f%%')

plt.savefig('FirstImage')
plt.show()

labels = ['never', 'No Info', 'former', 'current', 'not current', 'ever']
values = data['smoking_history'].value_counts().values

plt.style.use('fivethirtyeight')
plt.figure(figsize=(15, 10))
plt.subplot(1, 2, 1)
sns.countplot(x=data['smoking_history'], data=data)
plt.subplot(1, 2, 2)
plt.pie(values, labels=labels, autopct='%1.1f%%')

plt.savefig('Image')
plt.show()

numerical = ['age', 'bmi', 'blood_glucose_level', 'HbA1c_level']
i = 0

while i < 4:
  plt.figure(figsize=(20, 8))
  plt.subplot(1, 2, 1)
  sns.distplot(data[numerical[i]])
  i += 1
  if i == 4:
    break
  plt.subplot(1, 2, 2)
  sns.distplot(data[numerical[i]])
  i += 1
  plt.show()

plt.savefig('2')

"""# **Preprocessing and Cleaning Data**"""

data.isnull().sum()

data.duplicated().sum()

"""

> **The number of duplicated values is 3854**

"""

data = data.drop_duplicates()

"""

> **Delete Outliers**

"""

test = data[['age', 'bmi', 'HbA1c_level', 'blood_glucose_level']]
z = np.abs(stats.zscore(test))
data = data[(z < 3).all(axis=1)]

data.shape

data['smoking_history'].replace({'never': 2, 'No Info': 3, 'current': 4, 'former': 5,
                                'not current': 6, 'ever': 7}, inplace=True)

data['gender'].replace({'Male': 2, 'Female': 3, 'Other': 3}, inplace=True)

data.head()

"""# **Exploring Categorical Features**"""

categorical_columns = ['gender', 'hypertension', 'heart_disease', 'smoking_history']

fig, axes = plt.subplots( 4 , 2 , figsize=( 20 , 30 ))
sns.set_style( 'darkgrid' )
idx =  0
untuk  kolom  di  kategori_kolom:
    sns.countplot(data=data, y=col, palet= 'magma' , orient= 'h' ,
                  ax=axes[idx][ 0 ]).set_title( f 'Count of  {col} ' , fontize= '20' ) untuk  container  di  axes[idx][ 0 ].containers :         sumbu[idx][ 0 ].bar_label(wadah)     sns.countplot(data=data, y=col, palet= 'mako' , orient= 'h' , hue= 'diabetes' ,                   ax=axes[idx][ 1 ]).set_title( f 'Jumlah  {col}  per Diabetes' , fontize= '20' ) untuk  wadah  di  axes[idx][ 1 ].containers:         axes[idx][ 1 ].bar_label(container)     idx + = 1 plt.tampilkan()

"""# **Exploring Numerical Features**"""

numerical_columns = ['age', 'bmi', 'HbA1c_level', 'blood_glucose_level']

fig, axes = plt.subplots(4,2, figsize=(20,35))
sns.set_style('darkgrid')
idx = 0
for col in (numerical_columns):
    sns.kdeplot(data=data, x=col, palette='Greens',fill=True , hue='diabetes',
                ax=axes[idx][0]).set_title(f'Distribution of {col}', fontsize='16')
    sns.boxplot(data=data, x=col, palette='flare' , y='diabetes', orient='h',
                ax=axes[idx][1]).set_title(f'BoxPlot of {col}', fontsize='16')
    idx +=1
plt.show()

"""# **Correlation Between The Features**"""

fig=plt.gcf()
fig.set_size_inches(10,8)
plt.title('Correlation Between The Features')
a = sns.heatmap(data.corr(), annot=True, cmap='Pastel1', fmt='.2f', linewidths=0.2)
a.set_xticklabels(a.get_xticklabels(), rotation=60)
a.set_yticklabels(a.get_yticklabels())
plt.show()

# Pairplot based on Personal Loan
sns.set_palette(sns.color_palette("Paired", 8))
sns.pairplot(data, x_vars=['age', 'bmi', 'HbA1c_level', 'blood_glucose_level'], y_vars=['age', 'bmi', 'HbA1c_level', 'blood_glucose_level'], hue='diabetes',corner=True)
plt.show()

"""# **Data and Target Split**"""

target = data['diabetes']
data.drop('diabetes', axis=1, inplace=True)

data.corrwith(target).plot.bar(
    figsize=(15, 10), title='Correlation with Diabetes',
    fontsize=15, rot=90, grid=True)
plt.savefig('5')
plt.show()

"""# **Train Test Split**"""

xtrain, xtest, ytrain, ytest = train_test_split(data, target, test_size=0.35, random_state=42)

def metrics_calculator(y_test, y_pred, model_name):
    '''
    This function calculates all desired performance metrics for a given model.
    '''
    result = pd.DataFrame(data=[accuracy_score(y_test, y_pred),
                                precision_score(y_test, y_pred, average='macro'),
                                recall_score(y_test, y_pred, average='macro'),
                                f1_score(y_test, y_pred, average='macro')],
                          index=['Accuracy','Precision','Recall','F1-score'],
                          columns = [model_name])
    return result

"""# **Feature Scaling Using StandardScaler**"""

cols = xtrain.columns

scaler = StandardScaler()

xtrain = scaler.fit_transform(xtrain)

xtest = scaler.transform(xtest)

xtrain = pd.DataFrame(xtrain, columns=[cols])
xtest = pd.DataFrame(xtest, columns=[cols])

"""# **Modeling:**


> **Logistic Regression**


> **KNeighborsClassifier**


> **Decision Tree Classifier**


> **Random Forest Classfier**

# **Logistic Regression**
"""

lg = LogisticRegression()
param = {
    'penalty': ['l1', 'l2', 'elasticnet']}

gridSearch = GridSearchCV(lg, param, cv=5, scoring='accuracy')
gridSearch.fit(xtrain, ytrain)

Logistic = gridSearch.best_estimator_
Logistic.fit(xtrain, ytrain)

ypred = Logistic.predict(xtest)

print('Model Accuracy Score: {0:0.4f}'. format(accuracy_score(ytest, ypred)))

kf = StratifiedKFold(n_splits=5, shuffle=False)

score = cross_val_score(Logistic, xtrain, ytrain, cv=kf, scoring='accuracy')
lg_model_cv_score = score.mean()
lg_model_cv_stdev = stdev(score)
print('Cross Validation Accuracy scores are: {}'.format(score))

accuracy = ['Cross Validation Accuracy']
random_a = pd.DataFrame({'CV Mean':lg_model_cv_score,'Std':lg_model_cv_stdev},index=accuracy)
random_a

fig, ax = plt.subplots(figsize=(8, 5), dpi=90)
sns.set_style('darkgrid')
ConfusionMatrixDisplay.from_estimator(Logistic, xtest, ytest, ax=ax, colorbar=False, cmap='Blues')
plt.title('Confusion Matrix of Logistic Regression')
plt.grid()

lg_result = metrics_calculator(ytest, ypred, 'Logistic')
lg_result

fig, ax = plt.subplots(figsize=(8, 5), dpi=90)
RocCurveDisplay.from_estimator(Logistic, xtest, ytest, ax=ax, name='Logistic')
plt.plot([0, 1], [0, 1], linestyle='--', linewidth=2)

sns.set_style('darkgrid')

plt.show()

"""# **DecisionTreeClassifier**"""

tree = DecisionTreeClassifier()

param = {
    'criterion': ['gini', 'entropy'],
    'max_depth': [i for i in range(1, 10)]}

gridSearch = GridSearchCV(tree, param, cv=5, scoring='neg_mean_squared_error')
gridSearch.fit(xtrain, ytrain)

Tree = gridSearch.best_estimator_
Tree.fit(xtrain, ytrain)

ypred = Tree.predict(xtest)

kf = StratifiedKFold(n_splits=10, shuffle=False)

score = cross_val_score(Tree, xtrain, ytrain, cv=kf, scoring='accuracy')
tree_model_cv_score = score.mean()
tree_model_cv_stdev = stdev(score)
print('Cross Validation Accuracy scores are: {}'.format(score))

accuracy = ['Cross Validation Accuracy']
random_a = pd.DataFrame({'CV Mean':tree_model_cv_score,'Std':tree_model_cv_stdev},index=accuracy)
random_a

fig, ax = plt.subplots(figsize=(8, 5), dpi=90)
sns.set_style('darkgrid')
ConfusionMatrixDisplay.from_estimator(Tree, xtest, ytest, ax=ax, colorbar=False, cmap='Blues')
plt.title('Confusion Matrix of Decision Tree')
plt.grid()

tree_result = metrics_calculator(ytest, ypred, 'Decision Tree')
tree_result

fig, ax = plt.subplots(figsize=(8, 5), dpi=90)
RocCurveDisplay.from_estimator(Tree, xtest, ytest, ax=ax, name='Decision Tree')
plt.plot([0, 1], [0, 1], linestyle='--', linewidth=2, c='blue')

sns.set_style('darkgrid')

plt.show()

"""# **KNeighborsCLassifier**"""

knn = KNeighborsClassifier()
param = {
    'n_neighbors': [3, 5, 7, 10],
    'weights': ['unoform', 'distance']}

gridSearch = GridSearchCV(knn, param, cv=5, scoring='accuracy')
gridSearch.fit(xtrain, ytrain)

KNN = gridSearch.best_estimator_
KNN.fit(xtrain, ytrain)

ypred = KNN.predict(xtest)

print('Model Accuracy Score: {0:0.4f}'. format(accuracy_score(ytest, ypred)))

kf = StratifiedKFold(n_splits=10, shuffle=False)

score = cross_val_score(Logistic, xtrain, ytrain, cv=kf, scoring='accuracy')
knn_model_cv_score = score.mean()
knn_model_cv_stdev = stdev(score)
print('Cross Validation Accuracy scores are: {}'.format(score))

accuracy = ['Cross Validation Accuracy']
random_a = pd.DataFrame({'CV Mean':knn_model_cv_score,'Std':knn_model_cv_stdev},index=accuracy)
random_a

fig, ax = plt.subplots(figsize=(8, 5), dpi=90)
sns.set_style('darkgrid')
ConfusionMatrixDisplay.from_estimator(KNN, xtest, ytest, ax=ax, colorbar=False, cmap='Blues')
plt.title('Confusion Matrix of KNN')
plt.grid()

knn_result = metrics_calculator(ytest, ypred, 'KNN')
knn_result

fig, ax = plt.subplots(figsize=(8, 5), dpi=90)
RocCurveDisplay.from_estimator(KNN, xtest, ytest, ax=ax, name='KNN')
plt.plot([0, 1], [0, 1], linestyle='--', linewidth=2)

sns.set_style('darkgrid')

plt.show()

"""# **Random Forest**"""

random = RandomForestClassifier()
parameter = {
    'criterion': ['gini', 'entropy']}

gridSearch = GridSearchCV(random, parameter, cv=5, scoring='accuracy')
gridSearch.fit(xtrain, ytrain)

Random = gridSearch.best_estimator_
Random.fit(xtrain, ytrain)

ypred = Random.predict(xtest)

kf = StratifiedKFold(n_splits=10, shuffle=False)

score = cross_val_score(Random, xtrain, ytrain, cv=kf, scoring='accuracy')
r_model_cv_score = score.mean()
r_model_cv_stdev = stdev(score)
print('Cross Validation Accuracy scores are: {}'.format(score))

accuracy = ['Cross Validation Accuracy']
random_a = pd.DataFrame({'CV Mean':r_model_cv_score,'Std':r_model_cv_stdev},index=accuracy)
random_a

fig, ax = plt.subplots(figsize=(8, 5), dpi=90)
sns.set_style('darkgrid')
ConfusionMatrixDisplay.from_estimator(Random, xtest, ytest, ax=ax, colorbar=False, cmap='Blues')
plt.title('Confusion Matrix of Random Forest')
plt.grid()

r_result = metrics_calculator(ytest, ypred, 'Random')
r_result

fig, ax = plt.subplots(figsize=(8, 5), dpi=90)
RocCurveDisplay.from_estimator(Random, xtest, ytest, ax=ax, name='RandomForest')
plt.plot([0, 1], [0, 1], linestyle='--', linewidth=2)

sns.set_style('darkgrid')

plt.show()

"""# **Conclusion**"""

Conclusion = pd.concat([lg_result, knn_result, tree_result, r_result], axis=1)
Conclusion

"""# **Best Algorithms: Decision Tree 97%**

**Feature Importances**
"""

plt.figure(figsize=(10, 5))
plt.title('Feature Importances', size=20)

plt.style.use('fivethirtyeight')
pd.Series(Tree.feature_importances_, index=data.columns).plot(kind='barh')
plt.show()

"""**Making Prediction System**"""

input_data_1 = (3,80.0,0,1,2,25.19,6.6,140)
input_data_2 = (3,54.0,0,0,3,27.32,6.6,80)
input_data_3 = (2,76.0,1,1,4,20.14,4.8,155)
input_data_4 = (3,61.0,0,0,6,39.36,9.0,140)
input_data_5 = (2,73.0,0,0,5,25.91,9.0,160)

input_data_1 = np.asarray(input_data_1).reshape(1, -1)
input_data_2 = np.asarray(input_data_2).reshape(1, -1)
input_data_3 = np.asarray(input_data_3).reshape(1, -1)
input_data_4 = np.asarray(input_data_4).reshape(1, -1)
input_data_5 = np.asarray(input_data_5).reshape(1, -1)

print(f'First--> {input_data_1}')
print()
print(f'Second--> {input_data_2}')
print()
print(f'Third-> {input_data_3}')
print()
print(f'fourth-> {input_data_4}')
print()
print(f'fifth-> {input_data_5}')

new_input_1 = scaler.transform(input_data_1)
new_input_2 = scaler.transform(input_data_2)
new_input_3 = scaler.transform(input_data_3)
new_input_4 = scaler.transform(input_data_4)
new_input_5 = scaler.transform(input_data_5)

prediction_1 = Tree.predict(new_input_1)
prediction_2 = Tree.predict(new_input_2)
prediction_3 = Tree.predict(new_input_3)
prediction_4 = Tree.predict(new_input_4)
prediction_5 = Tree.predict(new_input_5)

print(prediction_1[0])
if prediction_1[0] == 0:
      print('tidak diabetes')
else:
      print('diabetes')

print(prediction_2[0])
if prediction_2[0] == 0:
      print('tidak diabetes')
else:
      print('diabetes')

print(prediction_3[0])
if prediction_3[0] == 0:
      print('tidak diabetes')
else:
      print('diabetes')

print(prediction_4[0])
if prediction_4[0] == 0:
      print('tidak diabetes')
else:
      print('diabetes')

print(prediction_5[0])
if prediction_5[0] == 0:
      print('tidak diabetes')
else:
      print('diabetes')